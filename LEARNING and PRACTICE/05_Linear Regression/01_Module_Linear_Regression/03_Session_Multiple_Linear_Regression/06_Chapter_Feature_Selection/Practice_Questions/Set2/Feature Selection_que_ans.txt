QUESTION 1:

Recursive Feature Elimination
Read this document and answer the following question. 
Based on your reading, how do you think RFE measures the importance of the variable?


ANS:


MY ANS:

As we can give "n" of our choice, and things will be done automatically for us, to find best n predictors for the model, The next step we can do is manual elimination, hence we can combine both manual and automated approach here, saving time and efforts.


Suggested Answer

Recursive feature elimination is based on the idea of repeatedly constructing a model (for example, an SVM or a regression model) and choosing either the best or worst performing feature (for example, based on coefficients), setting the feature aside and then repeating the process with the rest of the features. This process is applied until all the features in the dataset are exhausted. Features are then ranked according to when they were eliminated. As such, it is a greedy optimisation for finding the best performing subset of features.

Read more at this link.
http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/



QUESTION 2:

Recursive Feature Elimination
Suppose you have to build five multiple linear regression models for five different datasets. You're planning to use about 10 variables for each of these models. The number of potential variables in each of these datasets are 15, 30, 65, 10, and 100. In which of these cases you would definitely need to use RFE?


ANS:

2nd, 3rd, and 5th cases

Feedback :
Correct! Though you might be thinking that while you would definitely need RFE in the 3rd and 5th cases, feature elimination in the 2nd dataset can be performed manually. But please note that while performing a manual elimination, you need to drop features one by one and bringing down the number from 30 to 10 can be very time-consuming. So it might be a good idea a perform an RFE to bring the number down to, say, 15, and then perform a manual feature elimination.
